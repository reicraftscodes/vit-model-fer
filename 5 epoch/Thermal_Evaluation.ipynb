{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0nzbnmNt8WL",
        "outputId": "c6ee2fd7-7f42-48ba-a6e7-a0de38d874b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLyvi_MguDUW",
        "outputId": "bdc00a11-6af8-4074-b14e-5ae8fdef0f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dissertation\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Dissertation/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDIQv81pzzLf",
        "outputId": "996fdbdc-9007-4fc1-c225-46624f73da12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset.py\t    inference.py\t   README.md\t      utils.py\n",
            "Data.zip\t    Main_Collab_ViT.ipynb  requirements.txt\n",
            "demo_multimodal.py  model.py\t\t   test_inference.py\n",
            "evaluate.py\t    quick_inference.py\t   train.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Pq5G0o_ubUu"
      },
      "outputs": [],
      "source": [
        "# Do not unzip again if you already unzipped it\n",
        "!unzip Data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4nSFGonuvbY"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dBzlP8Idw1tt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "from typing import Dict, List, Tuple, Optional, Union\n",
        "\n",
        "from dataset import create_multimodal_data_loaders, MultiModalFERDataset\n",
        "from model import create_multimodal_vit_model, get_optimizer_and_scheduler, ViTForFER, EarlyFusionViT, LateFusionViT\n",
        "from utils import EarlyStopping, MetricsTracker, save_checkpoint, load_checkpoint, PerformanceAnalyzer\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class MultiModalFERTrainer:\n",
        "    \"\"\"\n",
        "    Trainer class for Fine-tuning ViT on multimodal FER dataset\n",
        "    Supports RGB-only, Thermal-only, and Combined (RGB+Thermal) modes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: Union[ViTForFER, EarlyFusionViT, LateFusionViT],\n",
        "        train_loader: DataLoader,\n",
        "        test_loader: DataLoader,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
        "        device: torch.device,\n",
        "        config: Dict,\n",
        "        mode: str = 'rgb',\n",
        "        experiment_name: str = None\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "        self.config = config\n",
        "        self.mode = mode.lower()\n",
        "\n",
        "        # Setup experiment tracking\n",
        "        self.experiment_name = experiment_name or f\"multimodal_vit_fer_{self.mode}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        self.save_dir = os.path.join(config['output_dir'], self.experiment_name)\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "\n",
        "        # Setup file logging\n",
        "        self.setup_file_logging()\n",
        "\n",
        "        # Initialise tracking\n",
        "        self.tensorboard_writer = SummaryWriter(os.path.join(self.save_dir, 'tensorboard'))\n",
        "        self.metrics_tracker = MetricsTracker()\n",
        "        self.early_stopping = EarlyStopping(\n",
        "            patience=config['early_stopping_patience'],\n",
        "            min_delta=config['early_stopping_min_delta']\n",
        "        )\n",
        "\n",
        "        # Class names for metrics\n",
        "        self.class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprised']\n",
        "\n",
        "        # Initialise WandB if configured\n",
        "        if config.get('use_wandb', False):\n",
        "            wandb.init(\n",
        "                project=config['wandb_project'],\n",
        "                name=self.experiment_name,\n",
        "                config=config\n",
        "            )\n",
        "            wandb.watch(self.model)\n",
        "\n",
        "        # Loss function with class weights\n",
        "        if config.get('use_class_weights', False):\n",
        "            class_weights = self._get_class_weights()\n",
        "            self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "        else:\n",
        "            self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # File logger for training progress\n",
        "        self.file_logger.info(f\"Trainer initialized. Experiment: {self.experiment_name}\")\n",
        "        self.file_logger.info(f\"Save directory: {self.save_dir}\")\n",
        "        self.file_logger.info(f\"Training mode: {self.mode}\")\n",
        "        if self.mode == 'combined':\n",
        "            self.file_logger.info(f\"Fusion strategy: {config.get('fusion_strategy', 'early')}\")\n",
        "            self.file_logger.info(f\"Fusion type: {config.get('fusion_type', 'concat')}\")\n",
        "            self.file_logger.info(f\"Fusion layer: {config.get('fusion_layer', 'feature')}\")\n",
        "        self.file_logger.info(f\"Training samples: {len(self.train_loader.dataset):,}\")\n",
        "        self.file_logger.info(f\"Test samples: {len(self.test_loader.dataset):,}\")\n",
        "        self.file_logger.info(f\"Use augmented data: {config.get('use_augmented', False)}\")\n",
        "        self.file_logger.info(f\"Training configuration: {json.dumps(config, indent=2)}\")\n",
        "\n",
        "        logger.info(f\"Trainer initialized. Experiment: {self.experiment_name}\")\n",
        "        logger.info(f\"Save directory: {self.save_dir}\")\n",
        "        logger.info(f\"Training mode: {self.mode}\")\n",
        "\n",
        "    def setup_file_logging(self):\n",
        "        \"\"\"Setup file logging for training progress\"\"\"\n",
        "        log_file = os.path.join(self.save_dir, 'training_log.txt')\n",
        "\n",
        "        # Create file logger\n",
        "        self.file_logger = logging.getLogger(f'file_logger_{self.experiment_name}')\n",
        "        self.file_logger.setLevel(logging.INFO)\n",
        "\n",
        "        # Create file handler\n",
        "        file_handler = logging.FileHandler(log_file)\n",
        "        file_handler.setLevel(logging.INFO)\n",
        "\n",
        "        # Create formatter\n",
        "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "        file_handler.setFormatter(formatter)\n",
        "\n",
        "        # Add handler to logger\n",
        "        self.file_logger.addHandler(file_handler)\n",
        "\n",
        "    def _get_class_weights(self) -> torch.Tensor:\n",
        "        \"\"\"Calculate class weights for imbalanced dataset\"\"\"\n",
        "        # Create a temporary dataset to get class weights\n",
        "        temp_dataset = MultiModalFERDataset(\n",
        "            data_dir=self.config['data_dir'],\n",
        "            mode=self.mode,\n",
        "            split_ratio=0.8,\n",
        "            split_type='train',\n",
        "            use_augmented=self.config.get('use_augmented', False)\n",
        "        )\n",
        "        class_weights = temp_dataset.get_class_weights().to(self.device)\n",
        "        self.file_logger.info(f\"Class weights: {class_weights}\")\n",
        "        return class_weights\n",
        "\n",
        "    def train_epoch(self) -> Dict[str, float]:\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "\n",
        "        total_loss = 0\n",
        "        predictions = []\n",
        "        targets = []\n",
        "\n",
        "        # Progress bar\n",
        "        pbar = tqdm(self.train_loader, desc=\"Training\")\n",
        "\n",
        "        for batch_idx, batch in enumerate(pbar):\n",
        "            # Handle different input formats based on mode\n",
        "            if self.mode == 'combined':\n",
        "                data, labels = batch\n",
        "                rgb_images = data['rgb'].to(self.device)\n",
        "                thermal_images = data['thermal'].to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                # Forward pass for combined mode\n",
        "                outputs = self.model(rgb_images, thermal_images, labels)\n",
        "            else:\n",
        "                # Single modality mode (RGB or Thermal)\n",
        "                images, labels = batch\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                # Forward pass for single modality\n",
        "                outputs = self.model(images, labels)\n",
        "\n",
        "            loss = outputs['loss']\n",
        "            logits = outputs['logits']\n",
        "\n",
        "            # Backward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if self.config.get('gradient_clip_norm', None):\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    self.model.parameters(),\n",
        "                    self.config['gradient_clip_norm']\n",
        "                )\n",
        "\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "\n",
        "            # Track metrics\n",
        "            total_loss += loss.item()\n",
        "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "            targets.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'LR': f'{self.scheduler.get_last_lr()[0]:.6f}'\n",
        "            })\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        epoch_loss = total_loss / len(self.train_loader)\n",
        "        epoch_acc = accuracy_score(targets, predictions)\n",
        "        epoch_f1 = f1_score(targets, predictions, average='weighted')\n",
        "\n",
        "        metrics = {\n",
        "            'loss': epoch_loss,\n",
        "            'accuracy': epoch_acc,\n",
        "            'f1_score': epoch_f1,\n",
        "            'precision': precision_score(targets, predictions, average='weighted'),\n",
        "            'recall': recall_score(targets, predictions, average='weighted')\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def validate_epoch(self, loader: DataLoader) -> Dict[str, float]:\n",
        "        \"\"\"Validate for one epoch\"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        total_loss = 0\n",
        "        predictions = []\n",
        "        targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(loader, desc=\"Validating\"):\n",
        "                # Handle different input formats based on mode\n",
        "                if self.mode == 'combined':\n",
        "                    data, labels = batch\n",
        "                    rgb_images = data['rgb'].to(self.device)\n",
        "                    thermal_images = data['thermal'].to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "\n",
        "                    # Forward pass for combined mode\n",
        "                    outputs = self.model(rgb_images, thermal_images, labels)\n",
        "                else:\n",
        "                    # Single modality mode (RGB or Thermal)\n",
        "                    images, labels = batch\n",
        "                    images = images.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "\n",
        "                    # Forward pass for single modality\n",
        "                    outputs = self.model(images, labels)\n",
        "\n",
        "                loss = outputs['loss']\n",
        "                logits = outputs['logits']\n",
        "\n",
        "                # Track metrics\n",
        "                total_loss += loss.item()\n",
        "                predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "                targets.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        epoch_loss = total_loss / len(loader)\n",
        "        epoch_acc = accuracy_score(targets, predictions)\n",
        "        epoch_f1 = f1_score(targets, predictions, average='weighted')\n",
        "\n",
        "        metrics = {\n",
        "            'loss': epoch_loss,\n",
        "            'accuracy': epoch_acc,\n",
        "            'f1_score': epoch_f1,\n",
        "            'precision': precision_score(targets, predictions, average='weighted'),\n",
        "            'recall': recall_score(targets, predictions, average='weighted'),\n",
        "            'predictions': predictions,\n",
        "            'targets': targets\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def train(self, num_epochs: int) -> Dict:\n",
        "        \"\"\"Main training loop\"\"\"\n",
        "        self.file_logger.info(f\"Starting training for {num_epochs} epochs\")\n",
        "        logger.info(f\"Starting training for {num_epochs} epochs\")\n",
        "\n",
        "        best_f1 = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.file_logger.info(f\"\\n=== Epoch {epoch + 1}/{num_epochs} ===\")\n",
        "            logger.info(f\"\\n=== Epoch {epoch + 1}/{num_epochs} ===\")\n",
        "\n",
        "            # Training phase\n",
        "            train_metrics = self.train_epoch()\n",
        "\n",
        "            # Validation phase on test set (since we don't have separate validation)\n",
        "            val_metrics = self.validate_epoch(self.test_loader)\n",
        "\n",
        "            # Log metrics\n",
        "            self._log_metrics(epoch, train_metrics, val_metrics)\n",
        "\n",
        "            # Track metrics\n",
        "            self.metrics_tracker.update(\n",
        "                epoch + 1,\n",
        "                {\n",
        "                    'loss': train_metrics['loss'],\n",
        "                    'accuracy': train_metrics['accuracy'],\n",
        "                    'f1': train_metrics['f1_score'],\n",
        "                    'precision': train_metrics['precision'],\n",
        "                    'recall': train_metrics['recall']\n",
        "                },\n",
        "                {\n",
        "                    'loss': val_metrics['loss'],\n",
        "                    'accuracy': val_metrics['accuracy'],\n",
        "                    'f1': val_metrics['f1_score'],\n",
        "                    'precision': val_metrics['precision'],\n",
        "                    'recall': val_metrics['recall']\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Check for best model (based on validation F1 score)\n",
        "            if val_metrics['f1_score'] > best_f1:\n",
        "                best_f1 = val_metrics['f1_score']\n",
        "                self._save_checkpoint('best_model.pth', epoch, val_metrics)\n",
        "                self.file_logger.info(f\"New best model saved with F1: {best_f1:.4f}\")\n",
        "\n",
        "            # Early stopping check\n",
        "            if self.early_stopping(val_metrics['loss']):\n",
        "                self.file_logger.info(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
        "                logger.info(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
        "                break\n",
        "\n",
        "        # Save final model\n",
        "        self._save_checkpoint('last_model.pth', epoch, val_metrics)\n",
        "\n",
        "        # Generate final results\n",
        "        final_results = self._generate_final_results(val_metrics)\n",
        "\n",
        "        # Close logging\n",
        "        self.tensorboard_writer.close()\n",
        "\n",
        "        if self.config.get('use_wandb', False):\n",
        "            wandb.finish()\n",
        "\n",
        "        self.file_logger.info(\"Training completed!\")\n",
        "        logger.info(\"Training completed!\")\n",
        "\n",
        "        return final_results\n",
        "\n",
        "    def _log_metrics(self, epoch: int, train_metrics: Dict, val_metrics: Dict):\n",
        "        \"\"\"Log metrics to various tracking systems\"\"\"\n",
        "        # Console logging\n",
        "        logger.info(f\"Train - Loss: {train_metrics['loss']:.4f}, \"\n",
        "                   f\"Acc: {train_metrics['accuracy']:.4f}, \"\n",
        "                   f\"F1: {train_metrics['f1_score']:.4f}\")\n",
        "        logger.info(f\"Val   - Loss: {val_metrics['loss']:.4f}, \"\n",
        "                   f\"Acc: {val_metrics['accuracy']:.4f}, \"\n",
        "                   f\"F1: {val_metrics['f1_score']:.4f}\")\n",
        "\n",
        "        # File logging\n",
        "        self.file_logger.info(f\"Train - Loss: {train_metrics['loss']:.4f}, \"\n",
        "                             f\"Acc: {train_metrics['accuracy']:.4f}, \"\n",
        "                             f\"F1: {train_metrics['f1_score']:.4f}, \"\n",
        "                             f\"Precision: {train_metrics['precision']:.4f}, \"\n",
        "                             f\"Recall: {train_metrics['recall']:.4f}\")\n",
        "        self.file_logger.info(f\"Val   - Loss: {val_metrics['loss']:.4f}, \"\n",
        "                             f\"Acc: {val_metrics['accuracy']:.4f}, \"\n",
        "                             f\"F1: {val_metrics['f1_score']:.4f}, \"\n",
        "                             f\"Precision: {val_metrics['precision']:.4f}, \"\n",
        "                             f\"Recall: {val_metrics['recall']:.4f}\")\n",
        "\n",
        "        # TensorBoard logging\n",
        "        self.tensorboard_writer.add_scalars('Loss', {\n",
        "            'Train': train_metrics['loss'],\n",
        "            'Val': val_metrics['loss']\n",
        "        }, epoch)\n",
        "\n",
        "        self.tensorboard_writer.add_scalars('Accuracy', {\n",
        "            'Train': train_metrics['accuracy'],\n",
        "            'Val': val_metrics['accuracy']\n",
        "        }, epoch)\n",
        "\n",
        "        self.tensorboard_writer.add_scalars('F1 Score', {\n",
        "            'Train': train_metrics['f1_score'],\n",
        "            'Val': val_metrics['f1_score']\n",
        "        }, epoch)\n",
        "\n",
        "        # WandB logging\n",
        "        if self.config.get('use_wandb', False):\n",
        "            wandb.log({\n",
        "                'epoch': epoch,\n",
        "                'train_loss': train_metrics['loss'],\n",
        "                'val_loss': val_metrics['loss'],\n",
        "                'train_accuracy': train_metrics['accuracy'],\n",
        "                'val_accuracy': val_metrics['accuracy'],\n",
        "                'train_f1': train_metrics['f1_score'],\n",
        "                'val_f1': val_metrics['f1_score'],\n",
        "                'learning_rate': self.scheduler.get_last_lr()[0]\n",
        "            })\n",
        "\n",
        "    def _save_checkpoint(self, filename: str, epoch: int, metrics: Dict):\n",
        "        \"\"\"Save model checkpoint\"\"\"\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "            'metrics': metrics,\n",
        "            'config': self.config,\n",
        "            'mode': self.mode\n",
        "        }\n",
        "\n",
        "        save_path = os.path.join(self.save_dir, filename)\n",
        "        torch.save(checkpoint, save_path)\n",
        "        self.file_logger.info(f\"Checkpoint saved: {save_path}\")\n",
        "\n",
        "    def _generate_final_results(self, final_metrics: Dict) -> Dict:\n",
        "        \"\"\"Generate and save final results with detailed evaluation metrics\"\"\"\n",
        "        # Create performance analyzer\n",
        "        analyzer = PerformanceAnalyzer(self.class_names)\n",
        "\n",
        "        # Generate comprehensive analysis\n",
        "        detailed_analysis = analyzer.generate_detailed_analysis(\n",
        "            final_metrics['targets'],\n",
        "            final_metrics['predictions'],\n",
        "            self.save_dir\n",
        "        )\n",
        "\n",
        "        # Calculate additional metrics\n",
        "        from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "        # Overall metrics\n",
        "        overall_accuracy = accuracy_score(final_metrics['targets'], final_metrics['predictions'])\n",
        "\n",
        "        # Macro and Micro averages\n",
        "        macro_f1 = f1_score(final_metrics['targets'], final_metrics['predictions'], average='macro')\n",
        "        micro_f1 = f1_score(final_metrics['targets'], final_metrics['predictions'], average='micro')\n",
        "        macro_precision = precision_score(final_metrics['targets'], final_metrics['predictions'], average='macro')\n",
        "        micro_precision = precision_score(final_metrics['targets'], final_metrics['predictions'], average='micro')\n",
        "        macro_recall = recall_score(final_metrics['targets'], final_metrics['predictions'], average='macro')\n",
        "        micro_recall = recall_score(final_metrics['targets'], final_metrics['predictions'], average='micro')\n",
        "\n",
        "        # Per-class accuracy\n",
        "        per_class_accuracy = []\n",
        "        cm = confusion_matrix(final_metrics['targets'], final_metrics['predictions'])\n",
        "        for i in range(len(self.class_names)):\n",
        "            if cm[i, :].sum() > 0:\n",
        "                class_accuracy = cm[i, i] / cm[i, :].sum()\n",
        "            else:\n",
        "                class_accuracy = 0.0\n",
        "            per_class_accuracy.append(class_accuracy)\n",
        "\n",
        "        # Create comprehensive results dictionary\n",
        "        results = {\n",
        "            'mode': self.mode,\n",
        "            'experiment_name': self.experiment_name,\n",
        "            'final_metrics': {\n",
        "                'overall_accuracy': float(overall_accuracy),\n",
        "                'weighted_f1_score': float(final_metrics['f1_score']),\n",
        "                'weighted_precision': float(final_metrics['precision']),\n",
        "                'weighted_recall': float(final_metrics['recall']),\n",
        "                'macro_f1_score': float(macro_f1),\n",
        "                'micro_f1_score': float(micro_f1),\n",
        "                'macro_precision': float(macro_precision),\n",
        "                'micro_precision': float(micro_precision),\n",
        "                'macro_recall': float(macro_recall),\n",
        "                'micro_recall': float(micro_recall)\n",
        "            },\n",
        "            'per_class_metrics': {\n",
        "                'classes': self.class_names,\n",
        "                'accuracy': per_class_accuracy,\n",
        "                'f1_scores': detailed_analysis['class_performance'][self.class_names[0]]['f1_score'] if self.class_names else [],\n",
        "                'precision': [detailed_analysis['class_performance'][class_name]['precision'] for class_name in self.class_names],\n",
        "                'recall': [detailed_analysis['class_performance'][class_name]['recall'] for class_name in self.class_names]\n",
        "            },\n",
        "            'confusion_matrix': cm.tolist(),\n",
        "            'training_history': self.metrics_tracker.get_history(),\n",
        "            'detailed_analysis': detailed_analysis\n",
        "        }\n",
        "\n",
        "        # Fix per-class F1 scores extraction\n",
        "        results['per_class_metrics']['f1_scores'] = [\n",
        "            detailed_analysis['class_performance'][class_name]['f1_score']\n",
        "            for class_name in self.class_names\n",
        "        ]\n",
        "\n",
        "        # Save comprehensive results\n",
        "        results_file = os.path.join(self.save_dir, 'final_results.json')\n",
        "        with open(results_file, 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "\n",
        "        # Save evaluation summary\n",
        "        evaluation_summary = {\n",
        "            'experiment_name': self.experiment_name,\n",
        "            'mode': self.mode,\n",
        "            'overall_accuracy': float(overall_accuracy),\n",
        "            'macro_f1_score': float(macro_f1),\n",
        "            'micro_f1_score': float(micro_f1),\n",
        "            'weighted_f1_score': float(final_metrics['f1_score']),\n",
        "            'per_class_accuracy': {\n",
        "                class_name: float(acc) for class_name, acc in zip(self.class_names, per_class_accuracy)\n",
        "            }\n",
        "        }\n",
        "\n",
        "        summary_file = os.path.join(self.save_dir, 'evaluation_summary.json')\n",
        "        with open(summary_file, 'w') as f:\n",
        "            json.dump(evaluation_summary, f, indent=2)\n",
        "\n",
        "        # Plot training history\n",
        "        self.metrics_tracker.plot_metrics(self.save_dir)\n",
        "\n",
        "        # Log detailed results\n",
        "        self.file_logger.info(\"=== DETAILED EVALUATION RESULTS ===\")\n",
        "        self.file_logger.info(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "        self.file_logger.info(f\"Macro F1-Score: {macro_f1:.4f}\")\n",
        "        self.file_logger.info(f\"Micro F1-Score: {micro_f1:.4f}\")\n",
        "        self.file_logger.info(f\"Weighted F1-Score: {final_metrics['f1_score']:.4f}\")\n",
        "        self.file_logger.info(\"Per-class Accuracy:\")\n",
        "        for class_name, acc in zip(self.class_names, per_class_accuracy):\n",
        "            self.file_logger.info(f\"  {class_name}: {acc:.4f}\")\n",
        "        self.file_logger.info(\"Final evaluation completed with comprehensive metrics\")\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "def main(data_dir):\n",
        "    \"\"\"Main training function\"\"\"\n",
        "    # Configuration\n",
        "    config = {\n",
        "        'data_dir': data_dir,\n",
        "        'output_dir': './experiments',\n",
        "        'mode': 'thermal',  # 'rgb', 'thermal', or 'combined'\n",
        "        'fusion_strategy': 'early',  # 'early' or 'late' (for combined mode)\n",
        "        'fusion_type': 'concat',  # 'concat', 'add', or 'attention'\n",
        "        'fusion_layer': 'feature',  # 'feature' or 'prediction' (for late fusion)\n",
        "\n",
        "        # Model parameters\n",
        "        'model_name': 'google/vit-base-patch16-224-in21k',\n",
        "        'num_classes': 7,\n",
        "        'dropout_rate': 0.1,\n",
        "        'freeze_backbone': False,\n",
        "        'use_gradient_checkpointing': False,\n",
        "\n",
        "        # Training parameters\n",
        "        'batch_size': 32,\n",
        "        'num_epochs': 5,\n",
        "        'learning_rate': 5e-5,\n",
        "        'weight_decay': 0.01,\n",
        "        'warmup_steps': 500,\n",
        "        'gradient_clip_norm': 1.0,\n",
        "\n",
        "        # Data parameters\n",
        "        'image_size': 224,\n",
        "        'num_workers': 4,\n",
        "        'val_split': 0.2,\n",
        "        'use_augmented': True,\n",
        "        'use_class_weights': True,\n",
        "\n",
        "        # Early stopping\n",
        "        'early_stopping_patience': 10,\n",
        "        'early_stopping_min_delta': 0.001,\n",
        "\n",
        "        # Logging\n",
        "        'use_wandb': False,\n",
        "        'wandb_project': 'multimodal-fer'\n",
        "    }\n",
        "\n",
        "    # Device setup\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    logger.info(f\"Using device: {device}\")\n",
        "\n",
        "    # Create data loaders\n",
        "    logger.info(\"Creating data loaders...\")\n",
        "    train_loader, test_loader = create_multimodal_data_loaders(\n",
        "        data_dir=config['data_dir'],\n",
        "        mode=config['mode'],\n",
        "        batch_size=config['batch_size'],\n",
        "        image_size=config['image_size'],\n",
        "        num_workers=config['num_workers'],\n",
        "        val_split=config['val_split'],\n",
        "        use_augmented=config['use_augmented']\n",
        "    )\n",
        "\n",
        "    # Log dataset information\n",
        "    train_samples = len(train_loader.dataset)\n",
        "    test_samples = len(test_loader.dataset)\n",
        "    logger.info(f\"=== DATASET INFORMATION ===\")\n",
        "    logger.info(f\"Training Mode: {config['mode'].upper()}\")\n",
        "    if config['mode'] == 'combined':\n",
        "        logger.info(f\"Fusion Strategy: {config['fusion_strategy']}\")\n",
        "        logger.info(f\"Fusion Type: {config['fusion_type']}\")\n",
        "        logger.info(f\"Fusion Layer: {config['fusion_layer']}\")\n",
        "    logger.info(f\"Use Augmented Data: {config['use_augmented']}\")\n",
        "    logger.info(f\"Training Samples: {train_samples:,}\")\n",
        "    logger.info(f\"Test Samples: {test_samples:,}\")\n",
        "    logger.info(f\"Train Batches: {len(train_loader)}, Test Batches: {len(test_loader)}\")\n",
        "    logger.info(f\"Batch Size: {config['batch_size']}\")\n",
        "\n",
        "    # Create model\n",
        "    logger.info(\"Creating model...\")\n",
        "    model = create_multimodal_vit_model(\n",
        "        mode=config['mode'],\n",
        "        fusion_strategy=config['fusion_strategy'],\n",
        "        fusion_type=config['fusion_type'],\n",
        "        fusion_layer=config['fusion_layer'],\n",
        "        model_name=config['model_name'],\n",
        "        num_classes=config['num_classes'],\n",
        "        dropout_rate=config['dropout_rate'],\n",
        "        freeze_backbone=config['freeze_backbone'],\n",
        "        use_gradient_checkpointing=config['use_gradient_checkpointing']\n",
        "    )\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Calculate total training steps\n",
        "    total_steps = len(train_loader) * config['num_epochs']\n",
        "\n",
        "    # Create optimizer and scheduler\n",
        "    optimizer, scheduler = get_optimizer_and_scheduler(\n",
        "        model=model,\n",
        "        learning_rate=config['learning_rate'],\n",
        "        weight_decay=config['weight_decay'],\n",
        "        warmup_steps=config['warmup_steps'],\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = MultiModalFERTrainer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        test_loader=test_loader,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        device=device,\n",
        "        config=config,\n",
        "        mode=config['mode']\n",
        "    )\n",
        "\n",
        "    # Start training\n",
        "    logger.info(\"Starting training...\")\n",
        "    results = trainer.train(config['num_epochs'])\n",
        "\n",
        "    # Print final results\n",
        "    logger.info(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEb2nv-Txwye",
        "outputId": "cd6c9a32-c8aa-4b04-d5e0-4abadbe35de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Class weights: tensor([0.7622, 2.6192, 1.6786, 0.4934, 5.5782, 0.6646, 1.0005],\n",
            "       device='cuda:0')\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Trainer initialized. Experiment: multimodal_vit_fer_thermal_20250711_154616\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Save directory: ./experiments/multimodal_vit_fer_thermal_20250711_154616\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Training mode: thermal\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Training samples: 16,556\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Test samples: 4,139\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Use augmented data: True\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Training configuration: {\n",
            "  \"data_dir\": \"Data\",\n",
            "  \"output_dir\": \"./experiments\",\n",
            "  \"mode\": \"thermal\",\n",
            "  \"fusion_strategy\": \"early\",\n",
            "  \"fusion_type\": \"concat\",\n",
            "  \"fusion_layer\": \"feature\",\n",
            "  \"model_name\": \"google/vit-base-patch16-224-in21k\",\n",
            "  \"num_classes\": 7,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"freeze_backbone\": false,\n",
            "  \"use_gradient_checkpointing\": false,\n",
            "  \"batch_size\": 32,\n",
            "  \"num_epochs\": 5,\n",
            "  \"learning_rate\": 5e-05,\n",
            "  \"weight_decay\": 0.01,\n",
            "  \"warmup_steps\": 500,\n",
            "  \"gradient_clip_norm\": 1.0,\n",
            "  \"image_size\": 224,\n",
            "  \"num_workers\": 4,\n",
            "  \"val_split\": 0.2,\n",
            "  \"use_augmented\": true,\n",
            "  \"use_class_weights\": true,\n",
            "  \"early_stopping_patience\": 10,\n",
            "  \"early_stopping_min_delta\": 0.001,\n",
            "  \"use_wandb\": false,\n",
            "  \"wandb_project\": \"multimodal-fer\"\n",
            "}\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Starting training for 5 epochs\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:\n",
            "=== Epoch 1/5 ===\n",
            "Training: 100%|██████████| 517/517 [11:17<00:00,  1.31s/it, Loss=0.9104, LR=0.000005]\n",
            "Validating:   0%|          | 0/130 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Validating: 100%|██████████| 130/130 [00:45<00:00,  2.88it/s]\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Train - Loss: 1.5679, Acc: 0.3859, F1: 0.3796, Precision: 0.3805, Recall: 0.3859\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Val   - Loss: 1.0022, Acc: 0.6040, F1: 0.5985, Precision: 0.6312, Recall: 0.6040\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Checkpoint saved: ./experiments/multimodal_vit_fer_thermal_20250711_154616/best_model.pth\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:New best model saved with F1: 0.5985\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:\n",
            "=== Epoch 2/5 ===\n",
            "Training:   0%|          | 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 517/517 [08:45<00:00,  1.02s/it, Loss=0.6968, LR=0.000004]\n",
            "Validating:   0%|          | 0/130 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Validating: 100%|██████████| 130/130 [00:45<00:00,  2.88it/s]\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Train - Loss: 0.7543, Acc: 0.6955, F1: 0.6932, Precision: 0.6959, Recall: 0.6955\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Val   - Loss: 0.5376, Acc: 0.8002, F1: 0.8015, Precision: 0.8101, Recall: 0.8002\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Checkpoint saved: ./experiments/multimodal_vit_fer_thermal_20250711_154616/best_model.pth\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:New best model saved with F1: 0.8015\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:\n",
            "=== Epoch 3/5 ===\n",
            "Training:   0%|          | 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 517/517 [09:02<00:00,  1.05s/it, Loss=0.6362, LR=0.000002]\n",
            "Validating:   0%|          | 0/130 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Validating: 100%|██████████| 130/130 [00:45<00:00,  2.88it/s]\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Train - Loss: 0.4563, Acc: 0.8246, F1: 0.8245, Precision: 0.8250, Recall: 0.8246\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Val   - Loss: 0.3949, Acc: 0.8517, F1: 0.8542, Precision: 0.8670, Recall: 0.8517\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Checkpoint saved: ./experiments/multimodal_vit_fer_thermal_20250711_154616/best_model.pth\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:New best model saved with F1: 0.8542\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:\n",
            "=== Epoch 4/5 ===\n",
            "Training:   0%|          | 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 517/517 [09:02<00:00,  1.05s/it, Loss=0.3453, LR=0.000001]\n",
            "Validating:   0%|          | 0/130 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Validating: 100%|██████████| 130/130 [00:44<00:00,  2.92it/s]\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Train - Loss: 0.3493, Acc: 0.8676, F1: 0.8676, Precision: 0.8682, Recall: 0.8676\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Val   - Loss: 0.3259, Acc: 0.8753, F1: 0.8750, Precision: 0.8755, Recall: 0.8753\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Checkpoint saved: ./experiments/multimodal_vit_fer_thermal_20250711_154616/best_model.pth\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:New best model saved with F1: 0.8750\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:\n",
            "=== Epoch 5/5 ===\n",
            "Training:   0%|          | 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 517/517 [09:00<00:00,  1.05s/it, Loss=0.4758, LR=0.000000]\n",
            "Validating:   0%|          | 0/130 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Validating: 100%|██████████| 130/130 [00:44<00:00,  2.89it/s]\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Train - Loss: 0.3125, Acc: 0.8814, F1: 0.8816, Precision: 0.8820, Recall: 0.8814\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Val   - Loss: 0.3183, Acc: 0.8758, F1: 0.8759, Precision: 0.8773, Recall: 0.8758\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Checkpoint saved: ./experiments/multimodal_vit_fer_thermal_20250711_154616/best_model.pth\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:New best model saved with F1: 0.8759\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Checkpoint saved: ./experiments/multimodal_vit_fer_thermal_20250711_154616/last_model.pth\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:=== DETAILED EVALUATION RESULTS ===\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Overall Accuracy: 0.8758\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Macro F1-Score: 0.8785\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Micro F1-Score: 0.8758\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Weighted F1-Score: 0.8759\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Per-class Accuracy:\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:  angry: 0.8294\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:  disgust: 0.9257\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:  fear: 0.8879\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:  happy: 0.8778\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:  neutral: 0.7802\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:  sad: 0.9743\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:  surprised: 0.7893\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Final evaluation completed with comprehensive metrics\n",
            "INFO:file_logger_multimodal_vit_fer_thermal_20250711_154616:Training completed!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Main training execution command\n",
        "   Edit the config dictionary in main() to customise training parameters\n",
        "   rgb, thermal, combined modes are available\n",
        "   early and late fusion strategies are available for combined\n",
        "\"\"\"\n",
        "data_dir = 'Data'\n",
        "main(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxonq0hwyYdb"
      },
      "source": [
        "**Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "G1Y-jPt8yaL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3b577a-03a2-4ee9-d97e-23adbec5b0f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model loaded successfully!\n",
            "Mode: thermal\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from inference import MultiModalFERInference\n",
        "# Load model\n",
        "print(f\"Loading model...\")\n",
        "inferencer = MultiModalFERInference('experiments/multimodal_vit_fer_thermal_20250711_154616/best_model.pth')\n",
        "print(f\"✓ Model loaded successfully!\")\n",
        "print(f\"Mode: {inferencer.mode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SjU-Tainydfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792d3286-9374-490b-cb9b-e927fe51a629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running inference...\n",
            "\n",
            "============================================================\n",
            "🎭 EMOTION RECOGNITION RESULT\n",
            "============================================================\n",
            "📊 Model Mode: THERMAL\n",
            "😊 Predicted Emotion: NEUTRAL\n",
            "🎯 Confidence: 49.7%\n",
            "\n",
            "🏆 Top 3 Predictions:\n",
            "   🥇 neutral: 49.7%\n",
            "   🥈 fear: 34.6%\n",
            "   🥉 angry: 11.7%\n",
            "\n",
            "📈 All Emotion Probabilities:\n",
            "        angry: ██░░░░░░░░░░░░░░░░░░  11.7%\n",
            "      disgust: ░░░░░░░░░░░░░░░░░░░░   0.2%\n",
            "         fear: ██████░░░░░░░░░░░░░░  34.6%\n",
            "        happy: ░░░░░░░░░░░░░░░░░░░░   1.6%\n",
            "      neutral: █████████░░░░░░░░░░░  49.7%\n",
            "          sad: ░░░░░░░░░░░░░░░░░░░░   1.8%\n",
            "    surprised: ░░░░░░░░░░░░░░░░░░░░   0.5%\n"
          ]
        }
      ],
      "source": [
        "# Run inference\n",
        "# Change the Data path Thermal or RGB\n",
        "print(f\"\\nRunning inference...\")\n",
        "result = inferencer.predict_single('Data/Thermal/T_Angry_1_KTFE.jpg', 'Data/Thermal/T_Angry_1_KTFE.jpg')\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎭 EMOTION RECOGNITION RESULT\")\n",
        "print(\"=\"*60)\n",
        "print(f\"📊 Model Mode: {result['mode'].upper()}\")\n",
        "print(f\"😊 Predicted Emotion: {result['predicted_class'].upper()}\")\n",
        "print(f\"🎯 Confidence: {result['confidence_percent']:.1f}%\")\n",
        "\n",
        "print(f\"\\n🏆 Top 3 Predictions:\")\n",
        "for i, pred in enumerate(result['top3_predictions'], 1):\n",
        "    emoji = \"🥇\" if i == 1 else \"🥈\" if i == 2 else \"🥉\"\n",
        "    print(f\"   {emoji} {pred['class']}: {pred['confidence']:.1f}%\")\n",
        "\n",
        "print(f\"\\n📈 All Emotion Probabilities:\")\n",
        "for emotion, prob in result['all_probabilities'].items():\n",
        "    bar_length = int(prob * 20)  # Scale to 20 chars\n",
        "    bar = \"█\" * bar_length + \"░\" * (20 - bar_length)\n",
        "    print(f\"   {emotion:>10}: {bar} {prob*100:5.1f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}